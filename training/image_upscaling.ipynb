{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjRR7UumGV7b"
   },
   "source": [
    "# Image Upscaling sử dụng kỹ thuật CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eie0N6LMIRgH"
   },
   "source": [
    "## Thiết lập môi trường:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF4NAs34eQZm"
   },
   "source": [
    "### Cài đặt các công cụ cần thiết:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wanWEH_FCCu6",
    "outputId": "77f953bb-a755-49a4-abc4-ec7a2f00675a"
   },
   "outputs": [],
   "source": [
    "# Kết nối với Drive:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqQL44XlCI9H",
    "outputId": "951f4315-b1ac-4d3b-f1d2-1bc41e997b16"
   },
   "outputs": [],
   "source": [
    "# Clone repository từ Github:\n",
    "%cd /content/gdrive/MyDrive\n",
    "!git clone https://github.com/NHuy165/Group-Project---Image-Upscaling.git\n",
    "%cd Group-Project---Image-Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkVcBdiAeQZn",
    "outputId": "be3dc6bf-c10a-4116-82f5-922592694f75"
   },
   "outputs": [],
   "source": [
    "# Tải các thư viện cần thiết:\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-HmZZ6aeQZm"
   },
   "source": [
    "### Cài đặt thư viện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ_bcPchh3rQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpToRp_8GTAj"
   },
   "source": [
    "## Thu thập và xử lý dữ liệu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D7JNY4BPXgZ"
   },
   "source": [
    "### Thu thập dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNQfHE9WhpWO",
    "outputId": "ddcd9c6b-ea4a-4da7-ed5c-e7102ff39154"
   },
   "outputs": [],
   "source": [
    "url = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n",
    "# Dữ liệu gồm 500 hình ảnh.\n",
    "\n",
    "data_path = tf.keras.utils.get_file(origin=url, untar=True, fname=\"BSR\")\n",
    "root_path = os.path.join(data_path, \"BSDS500/data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftgCHfHBPcH_"
   },
   "source": [
    "### Phân loại dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcCW8Vnri-xp",
    "outputId": "6e33d920-6099-46b2-fa4f-10f17709f67c"
   },
   "outputs": [],
   "source": [
    "# Quy định về kích thước ảnh đầu ra mặc định (target_size) là 300x300 và ảnh đầu vào luôn được giảm xuống kích thước mặc định là 100x100. batch_size được quy định là 8.\n",
    "target_size = 300\n",
    "upscale_factor = 3\n",
    "input_size = target_size // upscale_factor\n",
    "batch_size = 8\n",
    "\n",
    "# Phân loại dữ liệu thành dữ liệu huấn luyện (training dataset) và dữ liệu kiểm tra (validation dataset), đồng thời chuẩn hóa kích thước thành 300x300.\n",
    "train_data_raw = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    root_path,\n",
    "    batch_size = batch_size,\n",
    "    label_mode=None,\n",
    "    image_size=(target_size, target_size),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "validate_data_raw = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    root_path,\n",
    "    batch_size = batch_size,\n",
    "    label_mode=None,\n",
    "    image_size=(target_size, target_size),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-twjELZaJcJ"
   },
   "source": [
    "### Xử lý dữ liệu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dux5donWgRxf"
   },
   "source": [
    "#### Chuẩn hóa pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRGSmBaZaQMX"
   },
   "outputs": [],
   "source": [
    "# Chuẩn hóa giá trị pixel của mỗi ảnh từ [0, 255] về [0, 1].\n",
    "def scale(img):\n",
    "    return (img)/255.0\n",
    "\n",
    "train_data = train_data_raw.map(scale)\n",
    "validate_data = validate_data_raw.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5loWx_igXV2"
   },
   "source": [
    "#### Tiền xử lý chi tiết:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3ftp8g7hzVF"
   },
   "outputs": [],
   "source": [
    "# process_input chuyển đổi ảnh sang không gian màu YUV và tách kênh màu Y, sau đó chỉnh lại kích cỡ ảnh.\n",
    "def process_input(img, new_size, upscale_factor):\n",
    "    img = tf.image.rgb_to_yuv(img)\n",
    "    y = tf.split(img, 3, axis = len(img.shape)-1)[0]\n",
    "    return tf.image.resize(y, [new_size, new_size], method=\"area\")\n",
    "\n",
    "\n",
    "def process_target(img):\n",
    "    img = tf.image.rgb_to_yuv(img) # Change the image format to yuv scale,\n",
    "    y = tf.split(img, 3, axis=len(img.shape)-1)[0]\n",
    "    return y\n",
    "\n",
    "train_data_scaled = train_data.map(\n",
    "    lambda img: (process_input(img, input_size, upscale_factor), process_target(img))\n",
    ")\n",
    "\n",
    "train_ds = train_data_scaled.prefetch(buffer_size=32)\n",
    "\n",
    "validate_data_scaled = validate_data.map(\n",
    "    lambda img: (process_input(img, input_size, upscale_factor), process_target(img))\n",
    ")\n",
    "\n",
    "valid_ds = validate_data_scaled.prefetch(buffer_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ghh5vZgcTm4"
   },
   "source": [
    "#### Hiển thị và kiểm tra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "id": "bqOxKbNojC4k",
    "outputId": "ef4230f7-9586-481c-89bd-66ec885073ab"
   },
   "outputs": [],
   "source": [
    "l = list(train_ds)\n",
    "\n",
    "img1 = tf.keras.preprocessing.image.array_to_img(l[0][1][0])\n",
    "plt.imshow(img1)\n",
    "plt.figure(figsize=(img1.size[0], img1.size[1]))\n",
    "plt.show()\n",
    "print(img1.size,\"\\n\")\n",
    "\n",
    "img2 = tf.keras.preprocessing.image.array_to_img(l[0][0][0])\n",
    "plt.imshow(img2)\n",
    "plt.figure(figsize=(img2.size[0], img2.size[1]))\n",
    "plt.show()\n",
    "print(img2.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLKencUJgzJt"
   },
   "source": [
    "## Xây dựng và huấn luyện mô hình:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNJbDjnMjgFa"
   },
   "source": [
    "### Xây dựng mô hình cơ sở:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlhQtUzSS5rE"
   },
   "source": [
    "#### Xây dựng lớp DepthToSpaceLayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKPM6zlUEoop"
   },
   "outputs": [],
   "source": [
    "# Custom layer wrapping tf.nn.depth_to_space\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class DepthToSpaceLayer(Layer):\n",
    "    def __init__(self, block_size, **kwargs):\n",
    "        super(DepthToSpaceLayer, self).__init__(**kwargs)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depth_to_space(inputs, block_size=self.block_size)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DepthToSpaceLayer, self).get_config()\n",
    "        config.update({\"block_size\": self.block_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a2Bwqu0TB1k"
   },
   "source": [
    "#### Xây dựng hàm tạo mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7M4zUSzXUtx"
   },
   "outputs": [],
   "source": [
    "def get_model(upscale_factor=3, channels=1):\n",
    "    conv_args = {\n",
    "        \"activation\": \"relu\",\n",
    "        \"kernel_initializer\": \"Orthogonal\",\n",
    "        \"padding\": \"same\",\n",
    "    }\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = layers.Conv2D(64, 5, **conv_args)(inputs)\n",
    "    x = layers.Conv2D(64, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(32, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(channels * (upscale_factor ** 2), 3, **conv_args)(x)\n",
    "    outputs = DepthToSpaceLayer(upscale_factor)(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddyipJuDk075"
   },
   "source": [
    "### Xây dựng công cụ theo dõi và đánh giá quá trình huấn luyện:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "favqoTxiTAZm"
   },
   "source": [
    "#### Xây dựng các hàm cần thiết:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJwvjCPHXhxi"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import PIL\n",
    "\n",
    "\n",
    "def plot_results(img, prefix, title):\n",
    "    \"\"\"Plot the result with zoom-in area.\"\"\"\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Create a new figure with a default 111 subplot.\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    plt.title(title)\n",
    "    # zoom-factor: 2.0, location: upper-left\n",
    "    axins = zoomed_inset_axes(ax, 2, loc=2)\n",
    "    axins.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    # Specify the limits.\n",
    "    x1, x2, y1, y2 = 200, 300, 100, 200\n",
    "    # Apply the x-limits.\n",
    "    axins.set_xlim(x1, x2)\n",
    "    # Apply the y-limits.\n",
    "    axins.set_ylim(y1, y2)\n",
    "\n",
    "    plt.yticks(visible=False)\n",
    "    plt.xticks(visible=False)\n",
    "\n",
    "    # Make the line.\n",
    "    mark_inset(ax, axins, loc1=1, loc2=3, fc=\"none\", ec=\"blue\")\n",
    "    plt.savefig(str(prefix) + \"-\" + title + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_lowres_image(img, upscale_factor):\n",
    "    \"\"\"Return low-resolution image to use as model input.\"\"\"\n",
    "    return img.resize(\n",
    "        (img.size[0] // upscale_factor, img.size[1] // upscale_factor),\n",
    "        PIL.Image.BICUBIC,\n",
    "    )\n",
    "\n",
    "\n",
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "    out = model.predict(input)\n",
    "\n",
    "    out_img_y = out[0]\n",
    "    out_img_y *= 255.0\n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lT83BZzTIu9"
   },
   "source": [
    "#### Xây dựng lớp kiểm tra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh1UiqfBXtZy"
   },
   "outputs": [],
   "source": [
    "dataset = os.path.join(root_path, \"images\")\n",
    "test_path = os.path.join(dataset, \"test\")\n",
    "\n",
    "test_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_path, fname)\n",
    "        for fname in os.listdir(test_path)\n",
    "        if fname.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "class ESPCNCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.test_img = get_lowres_image(load_img(test_img_paths[0]), upscale_factor)\n",
    "\n",
    "    # Store PSNR value in each epoch.\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.psnr = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"Mean PSNR for epoch: %.2f\" % (np.mean(self.psnr)))\n",
    "        if epoch % 20 == 0:\n",
    "            prediction = upscale_image(self.model, self.test_img)\n",
    "            plot_results(prediction, \"epoch-\" + str(epoch), \"prediction\")\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.psnr.append(10 * math.log10(1 / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEsHnf9BloTh"
   },
   "source": [
    "### Thiết lập quá trình huấn luyện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "P16fbklKXwcS",
    "outputId": "4b52b5e5-d3a1-45f1-e06e-ffb0e492cf32"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
    "\n",
    "checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model = get_model(upscale_factor=upscale_factor, channels=1)\n",
    "model.summary()\n",
    "\n",
    "callbacks = [ESPCNCallback(), early_stopping_callback, model_checkpoint_callback]\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjKLLP7TC8-6",
    "outputId": "e0acfc63-2dab-45af-a632-4c86ff8b2a8e"
   },
   "outputs": [],
   "source": [
    "# Tạo thư mục prediction để lưu các dự đoán của model\n",
    "!mkdir prediction\n",
    "%cd prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyZTq_EsltgY"
   },
   "source": [
    "### Huấn luyện và lưu mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "ZE2zG0bOiL3Q",
    "outputId": "5a2f748b-ec8b-43a4-b97b-3cc801b509db"
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=loss_fn,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=valid_ds, verbose=2\n",
    ")\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXNBn5YRCPxx",
    "outputId": "90a3ac80-f61e-4767-a33c-31d8bf81e9d3"
   },
   "outputs": [],
   "source": [
    "# Tạo thư mục Models và thư mục con image_upscale_model\n",
    "%cd ../\n",
    "!mkdir Models\n",
    "!mkdir Models/image_upscale_model\n",
    "\n",
    "# Lưu model vào thư mục Models/image_upscale_model\n",
    "model_save_path = 'Models/image_upscale_model/my_model.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GOmT3_YGB_a"
   },
   "source": [
    "## Chạy mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "aV0buFqctChb",
    "outputId": "434ed263-1e33-44fc-e2f5-0c97beb96625"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = 'Models/image_upscale_model/my_model.keras'\n",
    "model = keras.models.load_model(model_path, custom_objects={\"DepthToSpaceLayer\": DepthToSpaceLayer})\n",
    "\n",
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "    out = model.predict(input)\n",
    "\n",
    "    out_img_y = out[0]\n",
    "    out_img_y *= 255.0\n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img\n",
    "\n",
    "total_bicubic_psnr = 0.0\n",
    "total_test_psnr = 0.0\n",
    "\n",
    "for index, test_img_path in enumerate(test_img_paths[50:60]):\n",
    "    img = load_img(test_img_path)\n",
    "    lowres_input = get_lowres_image(img, upscale_factor)\n",
    "    w = lowres_input.size[0] * upscale_factor\n",
    "    h = lowres_input.size[1] * upscale_factor\n",
    "    highres_img = img.resize((w, h))\n",
    "    prediction = upscale_image(model, lowres_input)\n",
    "    lowres_img = lowres_input.resize((w, h))\n",
    "    lowres_img_arr = img_to_array(lowres_img)\n",
    "    highres_img_arr = img_to_array(highres_img)\n",
    "    predict_img_arr = img_to_array(prediction)\n",
    "    bicubic_psnr = tf.image.psnr(lowres_img_arr, highres_img_arr, max_val=255)\n",
    "    test_psnr = tf.image.psnr(predict_img_arr, highres_img_arr, max_val=255)\n",
    "\n",
    "    total_bicubic_psnr += bicubic_psnr\n",
    "    total_test_psnr += test_psnr\n",
    "\n",
    "    print(\n",
    "        \"PSNR of low resolution image and high resolution image is %.4f\" % bicubic_psnr\n",
    "    )\n",
    "    print(\"PSNR of predict and high resolution is %.4f\" % test_psnr)\n",
    "\n",
    "    # Lưu ảnh trực tiếp trong thư mục hiện tại\n",
    "    lowres_output_path = f\"lowres_{index}.png\"\n",
    "    highres_output_path = f\"highres_{index}.png\"\n",
    "    prediction_output_path = f\"prediction_{index}.png\"\n",
    "\n",
    "    lowres_img.save(lowres_output_path)\n",
    "    highres_img.save(highres_output_path)\n",
    "    prediction.save(prediction_output_path)\n",
    "\n",
    "\n",
    "    plot_results(lowres_img, index, \"lowres\")\n",
    "    plot_results(prediction, index, \"prediction\")\n",
    "    plot_results(highres_img, index, \"highres\")\n",
    "\n",
    "\n",
    "print(\"Avg. PSNR of lowres images is %.4f\" % (total_bicubic_psnr / 10))\n",
    "print(\"Avg. PSNR of reconstructions is %.4f\" % (total_test_psnr / 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9rGhV3jIjt7"
   },
   "source": [
    "## Chạy app.py để triển khai web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "qXa5-P16JDLp",
    "outputId": "de1f022f-41d0-455f-edfa-7bedc1a8029a"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.serve_kernel_port_as_window(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUvMyk2VI7n3",
    "outputId": "56677630-915a-47f9-fee6-547161724764"
   },
   "outputs": [],
   "source": [
    "!python app.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Eie0N6LMIRgH",
    "zpToRp_8GTAj",
    "_GOmT3_YGB_a"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
