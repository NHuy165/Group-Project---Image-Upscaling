{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjRR7UumGV7b"
   },
   "source": [
    "# Image Upscaling using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eie0N6LMIRgH"
   },
   "source": [
    "## Cài đặt thư viện:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ_bcPchh3rQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kết nối đến Drive và clone repo từ Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wanWEH_FCCu6",
    "outputId": "a52239a0-3c07-463b-d321-87772a0179c4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqQL44XlCI9H",
    "outputId": "7a0d634e-d9b5-4a20-b2aa-7f2597246c4f"
   },
   "outputs": [],
   "source": [
    "%cd /content/gdrive/MyDrive\n",
    "!git clone https://github.com/NHuy165/Group-Project---Image-Upscaling.git\n",
    "%cd Group-Project---Image-Upscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpToRp_8GTAj"
   },
   "source": [
    "## Thu thập và xử lý dữ liệu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D7JNY4BPXgZ"
   },
   "source": [
    "### Thu thập dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNQfHE9WhpWO"
   },
   "outputs": [],
   "source": [
    "url = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n",
    "# Dữ liệu gồm 500 hình ảnh.\n",
    "\n",
    "data_path = tf.keras.utils.get_file(origin=url, untar=True, fname=\"BSR\")\n",
    "root_path = os.path.join(data_path, \"BSDS500/data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftgCHfHBPcH_"
   },
   "source": [
    "### Phân loại dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcCW8Vnri-xp",
    "outputId": "c3afbfae-2dde-404c-95c3-edcdd5782681"
   },
   "outputs": [],
   "source": [
    "# Quy định về kích thước ảnh đầu ra mặc định (target_size) là 300x300 và ảnh đầu vào luôn được giảm xuống kích thước mặc định là 100x100. batch_size được quy định là 8.\n",
    "target_size = 300\n",
    "upscale_factor = 3\n",
    "input_size = target_size // upscale_factor\n",
    "batch_size = 8\n",
    "\n",
    "# Phân loại dữ liệu thành dữ liệu huấn luyện (training dataset) và dữ liệu kiểm tra (validation dataset), đồng thời chuẩn hóa kích thước thành 300x300.\n",
    "train_data_raw = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    root_path,\n",
    "    batch_size = batch_size,\n",
    "    label_mode=None,\n",
    "    image_size=(target_size, target_size),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "validate_data_raw = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    root_path,\n",
    "    batch_size = batch_size,\n",
    "    label_mode=None,\n",
    "    image_size=(target_size, target_size),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-twjELZaJcJ"
   },
   "source": [
    "### Xử lý dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRGSmBaZaQMX"
   },
   "outputs": [],
   "source": [
    "# Chuẩn hóa giá trị pixel của mỗi ảnh từ [0, 255] về [0, 1].\n",
    "def scale(img):\n",
    "    return (img)/255.0\n",
    "\n",
    "train_data = train_data_raw.map(scale)\n",
    "validate_data = validate_data_raw.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3ftp8g7hzVF"
   },
   "outputs": [],
   "source": [
    "# process_input chuyển đổi ảnh sang không gian màu YUV và tách kênh màu Y, sau đó chỉnh lại kích cỡ ảnh.\n",
    "def process_input(img, new_size, upscale_factor):\n",
    "    img = tf.image.rgb_to_yuv(img)\n",
    "    y = tf.split(img, 3, axis = len(img.shape)-1)[0]\n",
    "    return tf.image.resize(y, [new_size, new_size], method=\"area\")\n",
    "\n",
    "\n",
    "def process_target(img):\n",
    "    img = tf.image.rgb_to_yuv(img) # Change the image format to yuv scale,\n",
    "    y = tf.split(img, 3, axis=len(img.shape)-1)[0]\n",
    "    return y\n",
    "\n",
    "train_data_scaled = train_data.map(\n",
    "    lambda img: (process_input(img, input_size, upscale_factor), process_target(img))\n",
    ")\n",
    "\n",
    "train_ds = train_data_scaled.prefetch(buffer_size=32)\n",
    "\n",
    "validate_data_scaled = validate_data.map(\n",
    "    lambda img: (process_input(img, input_size, upscale_factor), process_target(img))\n",
    ")\n",
    "\n",
    "valid_ds = validate_data_scaled.prefetch(buffer_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ghh5vZgcTm4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "bqOxKbNojC4k",
    "outputId": "e8b660f8-53e4-4c2c-9a6c-293995482476"
   },
   "outputs": [],
   "source": [
    "l = list(train_ds)\n",
    "\n",
    "img1 = tf.keras.preprocessing.image.array_to_img(l[0][1][0])\n",
    "plt.imshow(img1)\n",
    "plt.figure(figsize=(img1.size[0], img1.size[1]))\n",
    "plt.show()\n",
    "print(img1.size,\"\\n\")\n",
    "\n",
    "img2 = tf.keras.preprocessing.image.array_to_img(l[0][0][0])\n",
    "plt.imshow(img2)\n",
    "plt.figure(figsize=(img2.size[0], img2.size[1]))\n",
    "plt.show()\n",
    "print(img2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKPM6zlUEoop"
   },
   "outputs": [],
   "source": [
    "# Custom layer wrapping tf.nn.depth_to_space\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class DepthToSpaceLayer(Layer):\n",
    "    def __init__(self, block_size, **kwargs):\n",
    "        super(DepthToSpaceLayer, self).__init__(**kwargs)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.depth_to_space(inputs, block_size=self.block_size)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DepthToSpaceLayer, self).get_config()\n",
    "        config.update({\"block_size\": self.block_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7M4zUSzXUtx"
   },
   "outputs": [],
   "source": [
    "def get_model(upscale_factor=3, channels=1):\n",
    "    conv_args = {\n",
    "        \"activation\": \"relu\",\n",
    "        \"kernel_initializer\": \"Orthogonal\",\n",
    "        \"padding\": \"same\",\n",
    "    }\n",
    "    inputs = keras.Input(shape=(None, None, channels))\n",
    "    x = layers.Conv2D(64, 5, **conv_args)(inputs)\n",
    "    x = layers.Conv2D(64, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(32, 3, **conv_args)(x)\n",
    "    x = layers.Conv2D(channels * (upscale_factor ** 2), 3, **conv_args)(x)\n",
    "    outputs = DepthToSpaceLayer(upscale_factor)(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJwvjCPHXhxi"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import PIL\n",
    "\n",
    "\n",
    "def plot_results(img, prefix, title):\n",
    "    \"\"\"Plot the result with zoom-in area.\"\"\"\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Create a new figure with a default 111 subplot.\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    plt.title(title)\n",
    "    # zoom-factor: 2.0, location: upper-left\n",
    "    axins = zoomed_inset_axes(ax, 2, loc=2)\n",
    "    axins.imshow(img_array[::-1], origin=\"lower\")\n",
    "\n",
    "    # Specify the limits.\n",
    "    x1, x2, y1, y2 = 200, 300, 100, 200\n",
    "    # Apply the x-limits.\n",
    "    axins.set_xlim(x1, x2)\n",
    "    # Apply the y-limits.\n",
    "    axins.set_ylim(y1, y2)\n",
    "\n",
    "    plt.yticks(visible=False)\n",
    "    plt.xticks(visible=False)\n",
    "\n",
    "    # Make the line.\n",
    "    mark_inset(ax, axins, loc1=1, loc2=3, fc=\"none\", ec=\"blue\")\n",
    "    plt.savefig(str(prefix) + \"-\" + title + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_lowres_image(img, upscale_factor):\n",
    "    \"\"\"Return low-resolution image to use as model input.\"\"\"\n",
    "    return img.resize(\n",
    "        (img.size[0] // upscale_factor, img.size[1] // upscale_factor),\n",
    "        PIL.Image.BICUBIC,\n",
    "    )\n",
    "\n",
    "\n",
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "    out = model.predict(input)\n",
    "\n",
    "    out_img_y = out[0]\n",
    "    out_img_y *= 255.0\n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ECh_baXX5Ci"
   },
   "outputs": [],
   "source": [
    "dataset = os.path.join(root_path, \"images\")\n",
    "test_path = os.path.join(dataset, \"test\")\n",
    "\n",
    "test_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_path, fname)\n",
    "        for fname in os.listdir(test_path)\n",
    "        if fname.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh1UiqfBXtZy"
   },
   "outputs": [],
   "source": [
    "class ESPCNCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.test_img = get_lowres_image(load_img(test_img_paths[0]), upscale_factor)\n",
    "\n",
    "    # Store PSNR value in each epoch.\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.psnr = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"Mean PSNR for epoch: %.2f\" % (np.mean(self.psnr)))\n",
    "        if epoch % 20 == 0:\n",
    "            prediction = upscale_image(self.model, self.test_img)\n",
    "            plot_results(prediction, \"epoch-\" + str(epoch), \"prediction\")\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        self.psnr.append(10 * math.log10(1 / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "P16fbklKXwcS",
    "outputId": "9d96ca6d-941e-4a26-bceb-5be4d35dd502"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
    "\n",
    "checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "model = get_model(upscale_factor=upscale_factor, channels=1)\n",
    "model.summary()\n",
    "\n",
    "callbacks = [ESPCNCallback(), early_stopping_callback, model_checkpoint_callback]\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjKLLP7TC8-6",
    "outputId": "065725b3-60a2-4765-e4b1-53dd6ed5e2d4"
   },
   "outputs": [],
   "source": [
    "# Tạo thư mục prediction để lưu các dự đoán của model\n",
    "!mkdir prediction\n",
    "%cd prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "ZE2zG0bOiL3Q",
    "outputId": "6042fdb0-8ae9-4072-d315-3750a3677c67"
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=loss_fn,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=valid_ds, verbose=2\n",
    ")\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "wkDhHzo3ZJZS",
    "outputId": "fee4aa02-ab7d-47e3-ca77-658740aa232a"
   },
   "outputs": [],
   "source": [
    "total_bicubic_psnr = 0.0\n",
    "total_test_psnr = 0.0\n",
    "\n",
    "for index, test_img_path in enumerate(test_img_paths[50:60]):\n",
    "    img = load_img(test_img_path)\n",
    "    lowres_input = get_lowres_image(img, upscale_factor)\n",
    "    w = lowres_input.size[0] * upscale_factor\n",
    "    h = lowres_input.size[1] * upscale_factor\n",
    "    highres_img = img.resize((w, h))\n",
    "    prediction = upscale_image(model, lowres_input)\n",
    "    lowres_img = lowres_input.resize((w, h))\n",
    "    lowres_img_arr = img_to_array(lowres_img)\n",
    "    highres_img_arr = img_to_array(highres_img)\n",
    "    predict_img_arr = img_to_array(prediction)\n",
    "    bicubic_psnr = tf.image.psnr(lowres_img_arr, highres_img_arr, max_val=255)\n",
    "    test_psnr = tf.image.psnr(predict_img_arr, highres_img_arr, max_val=255)\n",
    "\n",
    "    total_bicubic_psnr += bicubic_psnr\n",
    "    total_test_psnr += test_psnr\n",
    "\n",
    "    print(\n",
    "        \"PSNR of low resolution image and high resolution image is %.4f\" % bicubic_psnr\n",
    "    )\n",
    "    print(\"PSNR of predict and high resolution is %.4f\" % test_psnr)\n",
    "\n",
    "    # Lưu ảnh trực tiếp trong thư mục hiện tại\n",
    "    lowres_output_path = f\"lowres_{index}.png\"\n",
    "    highres_output_path = f\"highres_{index}.png\"\n",
    "    prediction_output_path = f\"prediction_{index}.png\"\n",
    "\n",
    "    lowres_img.save(lowres_output_path)\n",
    "    highres_img.save(highres_output_path)\n",
    "    prediction.save(prediction_output_path)\n",
    "\n",
    "    plot_results(lowres_img, index, \"lowres\")\n",
    "    plot_results(highres_img, index, \"highres\")\n",
    "    plot_results(prediction, index, \"prediction\")\n",
    "\n",
    "print(\"Avg. PSNR of lowres images is %.4f\" % (total_bicubic_psnr / 10))\n",
    "print(\"Avg. PSNR of reconstructions is %.4f\" % (total_test_psnr / 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXNBn5YRCPxx",
    "outputId": "357e7e91-0e05-4095-fb98-9e627bcfa896"
   },
   "outputs": [],
   "source": [
    "#Tạo thư mục Models và thư mục con image_upscale_model\n",
    "%cd ../\n",
    "!mkdir Models\n",
    "!mkdir Models/image_upscale_model\n",
    "\n",
    "#Lưu model vào thư mục Models/image_upscale_model\n",
    "model_save_path = 'Models/image_upscale_model/my_model.keras'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GOmT3_YGB_a"
   },
   "source": [
    "## With Pre Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "aV0buFqctChb",
    "outputId": "0a2d43df-5758-4bf8-911a-85834d118d07"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = 'Models/image_upscale_model/my_model.keras'\n",
    "model = keras.models.load_model(model_path, custom_objects={\"DepthToSpaceLayer\": DepthToSpaceLayer})\n",
    "\n",
    "def upscale_image(model, img):\n",
    "    \"\"\"Predict the result based on input image and restore the image as RGB.\"\"\"\n",
    "    ycbcr = img.convert(\"YCbCr\")\n",
    "    y, cb, cr = ycbcr.split()\n",
    "    y = img_to_array(y)\n",
    "    y = y.astype(\"float32\") / 255.0\n",
    "\n",
    "    input = np.expand_dims(y, axis=0)\n",
    "    out = model.predict(input)\n",
    "\n",
    "    out_img_y = out[0]\n",
    "    out_img_y *= 255.0\n",
    "\n",
    "    # Restore the image in RGB color space.\n",
    "    out_img_y = out_img_y.clip(0, 255)\n",
    "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
    "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
    "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
    "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
    "        \"RGB\"\n",
    "    )\n",
    "    return out_img\n",
    "\n",
    "total_bicubic_psnr = 0.0\n",
    "total_test_psnr = 0.0\n",
    "\n",
    "for index, test_img_path in enumerate(test_img_paths[50:60]):\n",
    "    img = load_img(test_img_path)\n",
    "    lowres_input = get_lowres_image(img, upscale_factor)\n",
    "    w = lowres_input.size[0] * upscale_factor\n",
    "    h = lowres_input.size[1] * upscale_factor\n",
    "    highres_img = img.resize((w, h))\n",
    "    prediction = upscale_image(model, lowres_input)\n",
    "    lowres_img = lowres_input.resize((w, h))\n",
    "    lowres_img_arr = img_to_array(lowres_img)\n",
    "    highres_img_arr = img_to_array(highres_img)\n",
    "    predict_img_arr = img_to_array(prediction)\n",
    "    bicubic_psnr = tf.image.psnr(lowres_img_arr, highres_img_arr, max_val=255)\n",
    "    test_psnr = tf.image.psnr(predict_img_arr, highres_img_arr, max_val=255)\n",
    "\n",
    "    total_bicubic_psnr += bicubic_psnr\n",
    "    total_test_psnr += test_psnr\n",
    "\n",
    "    print(\n",
    "        \"PSNR of low resolution image and high resolution image is %.4f\" % bicubic_psnr\n",
    "    )\n",
    "    print(\"PSNR of predict and high resolution is %.4f\" % test_psnr)\n",
    "\n",
    "    # Lưu ảnh trực tiếp trong thư mục hiện tại\n",
    "    lowres_output_path = f\"lowres_{index}.png\"\n",
    "    highres_output_path = f\"highres_{index}.png\"\n",
    "    prediction_output_path = f\"prediction_{index}.png\"\n",
    "\n",
    "    lowres_img.save(lowres_output_path)\n",
    "    highres_img.save(highres_output_path)\n",
    "    prediction.save(prediction_output_path)\n",
    "\n",
    "\n",
    "    plot_results(lowres_img, index, \"lowres\")\n",
    "    plot_results(prediction, index, \"prediction\")\n",
    "    plot_results(highres_img, index, \"highres\")\n",
    "\n",
    "\n",
    "print(\"Avg. PSNR of lowres images is %.4f\" % (total_bicubic_psnr / 10))\n",
    "print(\"Avg. PSNR of reconstructions is %.4f\" % (total_test_psnr / 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9rGhV3jIjt7"
   },
   "source": [
    "## Run app.py to implement web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "qXa5-P16JDLp",
    "outputId": "62f7f2c6-6c3f-4f31-f32d-7222251a8690"
   },
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.serve_kernel_port_as_window(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUvMyk2VI7n3",
    "outputId": "caffae8f-286c-438c-f8bc-b7ef4c6d852b"
   },
   "outputs": [],
   "source": [
    "!python app.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
